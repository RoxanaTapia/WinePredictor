{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "import random\n",
    "\n",
    "import sklearn.linear_model\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine Dataset\n",
    "df_wine = pd.read_csv(\"../df_wine.csv\", encoding = 'utf8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>points</th>\n",
       "      <th>year_of_wine</th>\n",
       "      <th>v_Abouriou</th>\n",
       "      <th>v_Aglianico</th>\n",
       "      <th>v_Airen</th>\n",
       "      <th>v_Albana</th>\n",
       "      <th>v_Albanello</th>\n",
       "      <th>v_Albariño</th>\n",
       "      <th>...</th>\n",
       "      <th>province_Spanish Islands</th>\n",
       "      <th>province_Tasmania</th>\n",
       "      <th>province_Texas</th>\n",
       "      <th>province_Tuscany</th>\n",
       "      <th>province_Veneto</th>\n",
       "      <th>province_Vermont</th>\n",
       "      <th>province_Victoria</th>\n",
       "      <th>province_Virginia</th>\n",
       "      <th>province_Washington</th>\n",
       "      <th>province_Western Australia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>87</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                          title  points  year_of_wine  \\\n",
       "0   14.0  Rainstorm 2013 Pinot Gris (Willamette Valley)      87          2013   \n",
       "\n",
       "   v_Abouriou  v_Aglianico  v_Airen  v_Albana  v_Albanello  v_Albariño  \\\n",
       "0           0            0        0         0            0           0   \n",
       "\n",
       "              ...              province_Spanish Islands  province_Tasmania  \\\n",
       "0             ...                                     0                  0   \n",
       "\n",
       "   province_Texas  province_Tuscany  province_Veneto  province_Vermont  \\\n",
       "0               0                 0                0                 0   \n",
       "\n",
       "   province_Victoria  province_Virginia  province_Washington  \\\n",
       "0                  0                  0                    0   \n",
       "\n",
       "   province_Western Australia  \n",
       "0                           0  \n",
       "\n",
       "[1 rows x 585 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE X and Y VARIABLES\n",
    "# df_wine = df_wine[df_wine['year_of_wine'] > 0]\n",
    "# df_X = df_wine.drop('points', axis=1)\n",
    "# df_X = df_X.drop('title', axis=1) # year was already extracted\n",
    "# df_Y = df_wine[['points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = df_wine[df_wine['year_of_wine'] > 0]\n",
    "df_X = df_wine[['year_of_wine']]\n",
    "df_Y = df_wine[['points']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test & Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 4, 'min_samples_split': 2}, -9.256891498510289)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search instead of a grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "regressor3 = DecisionTreeRegressor()\n",
    "param_dist = {'max_depth': sp_randint(2,16),\n",
    "              'min_samples_split': sp_randint(2,16)}\n",
    "\n",
    "n_iter_search = 20\n",
    "clfrs = RandomizedSearchCV(regressor3, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=5 , n_jobs=1, verbose=1,\n",
    "                                   n_iter=n_iter_search)\n",
    "clfrs.fit(df_X, df_Y)\n",
    "clfrs.best_params_, clfrs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.481371182060785\n",
      "Mean Squared Error: 9.310022623591765\n",
      "Root Mean Squared Error: 3.051232967767582\n"
     ]
    }
   ],
   "source": [
    "# Best result with Hyperparameter optimisation\n",
    "regressor = DecisionTreeRegressor(max_depth = clfrs.best_params_['max_depth'], min_samples_split = clfrs.best_params_['min_samples_split'])  \n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# The evaluation metrics\n",
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce Errors in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth for other calculations\n",
    "X_train_gt = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_of_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2010.658205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.598446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_of_wine\n",
       "count  68389.000000\n",
       "mean    2010.658205\n",
       "std        3.598446\n",
       "min     1945.000000\n",
       "25%     2009.000000\n",
       "50%     2011.000000\n",
       "75%     2013.000000\n",
       "max     2017.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['year_of_wine']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = X_train[['year_of_wine']].copy()\n",
    "year.columns = ['new_year']\n",
    "# df_wine = pd.concat([year, df_wine], axis=1)\n",
    "# df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_outliers(df):\n",
    "    rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]\n",
    "    # minimum sayi 1940 %0.5 e kadar artabilir\n",
    "    # max sayi 2018 %0.5 e kadar artabilir\n",
    "    j = 0\n",
    "    year_val = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if j%2 == 0:\n",
    "            year_val = row['year_of_wine'] * random.choice(rates) \n",
    "            df.at[i,'year_of_wine'] = year_val\n",
    "        j = j + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = introduce_outliers(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1e3950b8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train.groupby(['year_of_wine']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_of_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2009.026715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>799.175220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3830.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_of_wine\n",
       "count  68389.000000\n",
       "mean    2009.026715\n",
       "std      799.175220\n",
       "min      199.000000\n",
       "25%     1814.000000\n",
       "50%     2011.000000\n",
       "75%     2016.000000\n",
       "max     3830.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['year_of_wine']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO with Errors in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 13, 'min_samples_split': 12}, -9.270193774146813)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search instead of a grid search\n",
    "\n",
    "# combine training and testing\n",
    "x_data = pd.concat([X_train, X_test], axis=0)\n",
    "y_data = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "regressor3 = DecisionTreeRegressor()\n",
    "param_dist = {'max_depth': sp_randint(2,16),\n",
    "              'min_samples_split': sp_randint(2,16)}\n",
    "\n",
    "n_iter_search = 20\n",
    "clfrs = RandomizedSearchCV(regressor3, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=5 , n_jobs=1, verbose=1,\n",
    "                                   n_iter=n_iter_search)\n",
    "clfrs.fit(x_data, y_data)\n",
    "clfrs.best_params_, clfrs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor with Outliers in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.4822351800488294\n",
      "Mean Squared Error: 9.311941987986785\n",
      "Root Mean Squared Error: 3.0515474743131206\n"
     ]
    }
   ],
   "source": [
    "# Best result with Hyperparameter optimisation\n",
    "regressor = DecisionTreeRegressor(max_depth = clfrs.best_params_['max_depth'], min_samples_split = clfrs.best_params_['min_samples_split'])  \n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# The evaluation metrics\n",
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train[['year_of_wine']], axis=0)\n",
    "sd = np.std(X_train[['year_of_wine']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    sd = np.std(data, axis=0)\n",
    "    final_list = [x for x in data if (x > mean - 1 * sd)]\n",
    "    final_list = [x for x in final_list if (x < mean + 1 * sd)]\n",
    "    return final_list, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_outliers = outlier_detection(X_train['year_of_wine'].values)[0]\n",
    "mean = outlier_detection(X_train['year_of_wine'].values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = min(year_outliers)\n",
    "max_year = max(year_outliers)\n",
    "\n",
    "training_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# DROP\n",
    "# training_cleaned = training_data.drop(training_data[training_data.year_of_wine < min_year].index)\n",
    "# training_cleaned = training_cleaned.drop(training_cleaned[training_cleaned.year_of_wine > max_year].index)\n",
    "# X_train_outlier_cleaned = training_cleaned[training_cleaned.columns[:-1].tolist()]\n",
    "# y_train_outlier_cleaned = training_cleaned.filter(['points'], axis=1)\n",
    "\n",
    "# MEAN\n",
    "training_data.loc[training_data['year_of_wine'] < min_year, 'year_of_wine'] = round(mean)\n",
    "training_data.loc[training_data['year_of_wine'] > max_year, 'year_of_wine'] = round(mean)\n",
    "X_train_outlier_cleaned = training_data[training_data.columns[:-1].tolist()]\n",
    "y_train_outlier_cleaned = training_data.filter(['points'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRECISION & RECALL & RMSE FOR ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9350178912058439, 0.5261664887628127, 0.6370144012662379, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(X_train_gt['year_of_wine'].values, X_train_outlier_cleaned['year_of_wine'].values, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 183.56582027439967\n"
     ]
    }
   ],
   "source": [
    "# RMSE for Cleaned data and GT\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(X_train_gt['year_of_wine'].values, X_train_outlier_cleaned['year_of_wine'].values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 803.129210452162\n"
     ]
    }
   ],
   "source": [
    "# RMSE for Dirty data and GY\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(X_train_gt['year_of_wine'].values, X_train['year_of_wine'].values))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO optimisation with Clened Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 9, 'min_samples_split': 3}, -9.285710132465157)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search instead of a grid search\n",
    "\n",
    "# combine training and testing\n",
    "x_data = pd.concat([X_train_outlier_cleaned, X_test], axis=0)\n",
    "y_data = pd.concat([y_train_outlier_cleaned, y_test], axis=0)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "regressor3 = DecisionTreeRegressor()\n",
    "param_dist = {'max_depth': sp_randint(2,16),\n",
    "              'min_samples_split': sp_randint(2,16)}\n",
    "\n",
    "n_iter_search = 20\n",
    "clfrs = RandomizedSearchCV(regressor3, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=5 , n_jobs=1, verbose=1,\n",
    "                                   n_iter=n_iter_search)\n",
    "clfrs.fit(x_data, y_data)\n",
    "clfrs.best_params_, clfrs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor with Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.484442748576293\n",
      "Mean Squared Error: 9.316325658771026\n",
      "Root Mean Squared Error: 3.0522656599272326\n"
     ]
    }
   ],
   "source": [
    "# Best result with Hyperparameter optimisation\n",
    "regressor = DecisionTreeRegressor(max_depth = clfrs.best_params_['max_depth'], min_samples_split = clfrs.best_params_['min_samples_split'])  \n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train_outlier_cleaned, y_train_outlier_cleaned)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# The evaluation metrics\n",
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
