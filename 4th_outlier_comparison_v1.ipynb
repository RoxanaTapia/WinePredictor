{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "\n",
    "import sklearn.linear_model\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Wine Dataset\n",
    "df_wine = pd.read_csv(\"data/winemag-data-130k-v2.csv\", encoding = 'utf8', index_col=0)\n",
    "df_wine = df_wine.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                      int64\n",
      "country                   object\n",
      "description               object\n",
      "designation               object\n",
      "points                     int64\n",
      "price                    float64\n",
      "province                  object\n",
      "region_1                  object\n",
      "region_2                  object\n",
      "taster_name               object\n",
      "taster_twitter_handle     object\n",
      "title                     object\n",
      "variety                   object\n",
      "winery                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_wine.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGION CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP region_2 column since most of the records NULL and we have region_1\n",
    "df_wine[\"region\"] = df_wine[\"region_2\"].fillna(df_wine[\"region_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = df_wine[['country','province','region','price','title','variety','points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        63\n",
       "province       63\n",
       "region      21247\n",
       "price        8996\n",
       "title           0\n",
       "variety         1\n",
       "points          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of rows with NULL values\n",
    "df_wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101400, 7)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROP rows with NULL values\n",
    "df_wine=df_wine.dropna()\n",
    "df_wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    101400.000000\n",
       "mean         88.463343\n",
       "std           3.060467\n",
       "min          80.000000\n",
       "25%          86.000000\n",
       "50%          88.000000\n",
       "75%          91.000000\n",
       "max         100.000000\n",
       "Name: points, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine['points'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DUMMY VARIABLES\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Auto encodes any dataframe column of type category or object.\n",
    "def dummyEncode(df):\n",
    "        columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                df[feature] = le.fit_transform(df[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roxana/.virtualenvs/dojo3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>points</th>\n",
       "      <th>country_num</th>\n",
       "      <th>province_num</th>\n",
       "      <th>region_num</th>\n",
       "      <th>variety_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1009</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>13.0</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>477</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1009</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Navarra</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>639</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Vittoria</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Terre di Giurfo 2013 Belsito Frappato (Vittoria)</td>\n",
       "      <td>Frappato</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>999</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country           province               region  price  \\\n",
       "2      US             Oregon    Willamette Valley   14.0   \n",
       "3      US           Michigan  Lake Michigan Shore   13.0   \n",
       "4      US             Oregon    Willamette Valley   65.0   \n",
       "5   Spain     Northern Spain              Navarra   15.0   \n",
       "6   Italy  Sicily & Sardinia             Vittoria   16.0   \n",
       "\n",
       "                                               title             variety  \\\n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)          Pinot Gris   \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...            Riesling   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child...          Pinot Noir   \n",
       "5  Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...  Tempranillo-Merlot   \n",
       "6   Terre di Giurfo 2013 Belsito Frappato (Vittoria)            Frappato   \n",
       "\n",
       "   points  country_num  province_num  region_num  variety_num  \n",
       "2      87            6            43        1009          318  \n",
       "3      87            6            30         477          347  \n",
       "4      87            6            43        1009          322  \n",
       "5      87            5            39         639          430  \n",
       "6      87            4            50         999          131  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = dummyEncode(df_wine[['country','province','region','variety']])\n",
    "df_dummy.columns = ['country_num', 'province_num','region_num','variety_num']\n",
    "df_wine = pd.concat([df_wine, df_dummy], axis=1)\n",
    "df_wine.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Year from Title</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2013', '2012', '2011', '2010', '2007', '2009', '2014', '2015',\n",
       "       nan, '2016', '2', '2004', '2003', '2006', '2008', '2001', '2005',\n",
       "       '2002', '9', '46', '1887', '2000', '1999', '1991', '1997', '772',\n",
       "       '1', '41', '42', '44', '14', '33', '2017', '1637', '35', '39',\n",
       "       '1996', '4', '3', '012', '401', '181', '1492', '1898', '1998',\n",
       "       '7200', '1852', '50', '7', '12', '66', '1995', '1994', '1992',\n",
       "       '18401', '15', '5', '6', '1929', '240', '075', '17', '1875', '22',\n",
       "       '10', '786', '21', '8', '38', '351', '460', '1856', '91', '29',\n",
       "       '24', '25', '1990', '1988', '154', '511', '1827', '1860', '45',\n",
       "       '735', '1872', '52', '109', '204', '150', '1850', '337', '1877',\n",
       "       '30', '310', '1870', '100', '205', '1000', '1868', '16', '103',\n",
       "       '585', '413', '1989', '1993', '360', '32', '20', '1882', '51',\n",
       "       '375', '1821', '47', '158', '69', '128', '1947', '13', '1070',\n",
       "       '1985', '1927', '1904', '68', '1847', '1982', '1986', '90', '736',\n",
       "       '253', '010', '1752', '28', '1789', '75', '1987', '88', '1607',\n",
       "       '813', '1621', '31', '800', '1978', '1919', '868', '19', '013',\n",
       "       '1845', '09', '1150', '500', '61', '23', '555', '428', '18', '125',\n",
       "       '999', '36', '60', '01', '34', '1945', '26', '733'], dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REGEX: Extract first numbers from Title - FAILED BECAUSE THERE ARE MANY NUMBERS IN TITLES\n",
    "df = pd.DataFrame(df_wine['title'])\n",
    "df['year'] = df['title'].str.extract('(\\d+)')\n",
    "df.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: FIND ALL NUMBERS IN THE TITLE, ADD THEM TO A LIST VARIABLE\n",
    "def regex(x):\n",
    "    L = re.findall(r'\\d+', str(x))\n",
    "    L_str = \",\".join(str(x) for x in L)\n",
    "    return str(L_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_num_values'] = df['title'].apply(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>title_num_values</th>\n",
       "      <th>num_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Terre di Giurfo 2013 Belsito Frappato (Vittoria)</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year title_num_values  \\\n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)  2013             2013   \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...  2013             2013   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child...  2012             2012   \n",
       "5  Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...  2011             2011   \n",
       "6   Terre di Giurfo 2013 Belsito Frappato (Vittoria)  2013             2013   \n",
       "\n",
       "   num_count  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINDING HOW MANY NUMBERS DOES EACH TITLE INCLUDE\n",
    "df['num_count'] = df.title_num_values.str.count(',') + 1\n",
    "numeric_values_ct = df.num_count.max()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ALL THE NUMERIC VALUES IN THE TITLES FIND THEM AND ADD TO A NEW DATA FRAME AS COLUMNS\n",
    "def regex2(y):\n",
    "    L = re.findall(r'\\d+', str(y))\n",
    "    X = np.array([L])\n",
    "    new_L = []\n",
    "    for x in X:\n",
    "        a = x.tolist()\n",
    "        b = []\n",
    "        for i in range(1, numeric_values_ct + 1):\n",
    "            if len(a) == numeric_values_ct:\n",
    "                new_L.append(a)\n",
    "                break\n",
    "            else:\n",
    "                for j in range(0, numeric_values_ct - len(a)):\n",
    "                     b = a.extend([0])\n",
    "    return new_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = df['title'].apply(regex2)\n",
    "new_list1 = []\n",
    "new_list2 = []\n",
    "new_list3 = []\n",
    "new_list4 = []\n",
    "new_list5 = []\n",
    "for row in xx:\n",
    "    new_list1.append(row[0][0])\n",
    "    new_list2.append(row[0][1])\n",
    "    new_list3.append(row[0][2])\n",
    "    new_list4.append(row[0][3])\n",
    "    new_list5.append(row[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=0, column='N5', value= pd.Series(new_list5))\n",
    "df.insert(loc=0, column='N4', value= pd.Series(new_list4))\n",
    "df.insert(loc=0, column='N3', value= pd.Series(new_list3))\n",
    "df.insert(loc=0, column='N2', value= pd.Series(new_list2))\n",
    "df.insert(loc=0, column='N1', value= pd.Series(new_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET 0 FOR ALL THE VALUES WHICH HAS MORE THAN 4 DIGIT\n",
    "df.loc[df['N1'].astype(str).map(len) != 4 , 'N1'] = 0\n",
    "df.loc[df['N2'].astype(str).map(len) != 4 , 'N2'] = 0\n",
    "df.loc[df['N3'].astype(str).map(len) != 4 , 'N3'] = 0\n",
    "df.loc[df['N4'].astype(str).map(len) != 4 , 'N4'] = 0\n",
    "df.loc[df['N5'].astype(str).map(len) != 4 , 'N5'] = 0\n",
    "\n",
    "# SET 0 FOR ALL THE VALUES GREATER THAN CURRENT YEAR\n",
    "df.loc[df['N1'].astype(int) > 2018 , 'N1'] = 0\n",
    "df.loc[df['N2'].astype(int) > 2018 , 'N2'] = 0\n",
    "df.loc[df['N3'].astype(int) > 2018 , 'N3'] = 0\n",
    "df.loc[df['N4'].astype(int) > 2018 , 'N4'] = 0\n",
    "df.loc[df['N5'].astype(int) > 2018 , 'N5'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_of_wine'] = df[['N5','N4','N3','N2','N1']].astype(int).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2012, 2011, 2013, 2010, 2007, 2009, 2014, 2015,    0, 2016, 2004,\n",
       "       2003, 2006, 2008, 2001, 2005, 2000, 1999, 1991, 2002, 1997, 2017,\n",
       "       1996, 1998, 1995, 1994, 1992, 1990, 1989, 1993, 1947, 1988, 1927,\n",
       "       1904, 1982, 1985, 1987, 1978, 1986, 1945])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DELETE ALL THE YEARS BEFORE 1900 \n",
    "df = df[['title', 'year_of_wine']]\n",
    "df.loc[df['year_of_wine']  < 1900 , 'year_of_wine'] = 0\n",
    "df.year_of_wine.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT THE YEAR COLUMN TO MAIN DATAFRAME\n",
    "try:\n",
    "    if 'year_of_wine' not in df_wine:\n",
    "        df_wine = pd.concat([df_wine, df.year_of_wine], axis=1)\n",
    "except (RuntimeError, TypeError, NameError):\n",
    "    print(\"Error: concating year to main dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>points</th>\n",
       "      <th>country_num</th>\n",
       "      <th>province_num</th>\n",
       "      <th>region_num</th>\n",
       "      <th>variety_num</th>\n",
       "      <th>year_of_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1009</td>\n",
       "      <td>318</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>13.0</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>477</td>\n",
       "      <td>347</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1009</td>\n",
       "      <td>322</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  province               region  price  \\\n",
       "2      US    Oregon    Willamette Valley   14.0   \n",
       "3      US  Michigan  Lake Michigan Shore   13.0   \n",
       "4      US    Oregon    Willamette Valley   65.0   \n",
       "\n",
       "                                               title     variety  points  \\\n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)  Pinot Gris      87   \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...    Riesling      87   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child...  Pinot Noir      87   \n",
       "\n",
       "   country_num  province_num  region_num  variety_num  year_of_wine  \n",
       "2            6            43        1009          318          2012  \n",
       "3            6            30         477          347          2011  \n",
       "4            6            43        1009          322          2013  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert categorical variables to numeric with One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-811f4d941991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Variety\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_variety\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariety\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_variety\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'v_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_variety\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# naming the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_wine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_wine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_variety\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# combine main dataframe with country matrix dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_wine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# drop the country attribute since different attributes per country value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_get_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         return self._wrap_result(result, use_codes=(not self._is_categorical),\n\u001b[0;32m-> 2549\u001b[0;31m                                  name=name, expand=True)\n\u001b[0m\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_translate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, use_codes, name, expand)\u001b[0m\n\u001b[1;32m   2024\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m                 \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2026\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2027\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m                 \u001b[0;31m# Must be a Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   7495\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7496\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m-> 7497\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m   7498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   7552\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7553\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[0;32m-> 7554\u001b[0;31m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m   7555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   7619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7621\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   7619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7621\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   7615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7617\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7618\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Variety\n",
    "df_variety = df_wine.variety.str.get_dummies()\n",
    "df_variety.columns = ['v_' + col for col in df_variety.columns] # naming the columns\n",
    "df_wine = pd.concat([df_wine, df_variety], axis=1) # combine main dataframe with country matrix dataframe\n",
    "df_wine = df_wine.drop('variety', axis=1) # drop the country attribute since different attributes per country value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country\n",
    "df_country = df_wine.country.str.get_dummies() # get the pivot of the country attribte\n",
    "df_country.columns = ['country_' + col for col in df_country.columns] # naming the columns\n",
    "df_wine = pd.concat([df_wine, df_country], axis=1) # combine main dataframe with country matrix dataframe\n",
    "df_wine = df_wine.drop('country', axis=1) # drop the country attribute since different attributes per country value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Province\n",
    "df_province = df_wine.province.str.get_dummies() # get the pivot of the country attribte\n",
    "df_province.columns = ['province_' + col for col in df_province.columns] # naming the columns\n",
    "df_wine = pd.concat([df_wine, df_province], axis=1) # combine main dataframe with country matrix dataframe\n",
    "df_wine = df_wine.drop('province', axis=1) # drop the country attribute since different attributes per country value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Region\n",
    "# df_region = df_wine.region.str.get_dummies() # get the pivot of the country attribte\n",
    "# df_region.columns = ['region_' + col for col in df_province.columns] # naming the columns\n",
    "# df_wine = pd.concat([df_wine, df_region], axis=1) # combine main dataframe with country matrix dataframe\n",
    "df_wine = df_wine.drop('region', axis=1) # drop the country attribute since different attributes per country value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE X and Y VARIABLES\n",
    "df_wine = df_wine.drop('variety_num', axis=1) # drop the country attribute since different attributes per country value\n",
    "df_wine = df_wine.drop('country_num', axis=1) # drop the country attribute since different attributes per country value\n",
    "df_wine = df_wine.drop('province_num', axis=1) # drop the country attribute since different attributes per country value\n",
    "df_wine = df_wine.drop('region_num', axis=1) # drop the country attribute since different attributes per country value\n",
    "df_wine = df_wine[df_wine['year_of_wine'] > 0]\n",
    "df_X = df_wine.drop('points', axis=1)\n",
    "df_X = df_X.drop('title', axis=1) # year was already extracted\n",
    "df_Y = df_wine[['points']]\n",
    "print(df_X.shape)\n",
    "print(df_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFORMATION GAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "scores = []\n",
    "\n",
    "num_features = len(df_X.columns)\n",
    "for i in range(num_features):\n",
    "    col = df_X.columns[i]\n",
    "    scores_col = cross_val_score(lm, df_X[col].values.reshape(-1,1), df_Y.values.ravel(), cv=10, scoring='neg_mean_squared_error')\n",
    "    best_score = np.mean(np.sqrt(-scores_col))\n",
    "    scores.append((best_score, col))\n",
    "\n",
    "print(sorted(scores, reverse = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X = df_X.drop('title', axis=1) # year was already extracted\n",
    "# df_Y = df_wine[['points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Grid Search For Hyper Parameter Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result without Hyperparameter optimisation\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"# Best result WITHOUT hyperparameter optimisation #\")\n",
    "print(\"RMSE: %.4f\" % np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter selection\n",
    "# parameters = {'fit_intercept':[True,False],\n",
    "#               'normalize':[True,False], \n",
    "#               'copy_X':[True, False]}\n",
    "\n",
    "# gd_sr = GridSearchCV(estimator=lm,  \n",
    "#                      param_grid=parameters,\n",
    "#                      scoring=\"neg_mean_squared_error\",\n",
    "#                      cv=10)\n",
    "\n",
    "# gd_sr.fit(X_train, y_train)  \n",
    "\n",
    "# best_parameters = gd_sr.best_params_  \n",
    "# print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result with Hyperparameter optimisation\n",
    "lm2 = linear_model.LinearRegression(fit_intercept = True, normalize = False, copy_X = True )\n",
    "\n",
    "# Train the model using the training sets\n",
    "lm2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred2 = lm2.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"# Best result WITH hyperparameter optimisation #\")\n",
    "print(\"RMSE: %.4f\" % np.sqrt(metrics.mean_squared_error(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Outliers in Test Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression WITH outliers in Training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sets also have outliers\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "y_predictions_3 = lm.predict(X_test)\n",
    "\n",
    "w = model.coef_ # parameters of model\n",
    "b = model.intercept_ #intercept of model\n",
    "\n",
    "# print(\"coeficient: \", w)\n",
    "# print(\"intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "# store results\n",
    "ax3_y_test = deepcopy(y_test)\n",
    "ax3_y_predictions = deepcopy(y_predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "print ('Accuracy:', model.score(X_test, ax3_y_test))\n",
    "# Root mean squared error (RMSE)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(ax3_y_test, ax3_y_predictions)))\n",
    "# Mean absolute error (MAE)\n",
    "mae_3 = metrics.mean_absolute_error(ax3_y_test, ax3_y_predictions)\n",
    "print('MAE:', mae_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression W/O outliers in Training Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean test data\n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "# store clean training data\n",
    "X_train_clean = deepcopy(X_train)\n",
    "y_train_clean = deepcopy(y_train)\n",
    "\n",
    "# remove outliers from training data\n",
    "print(\"Training data with outliers\", X_train_clean.shape, y_train_clean.shape)\n",
    "\n",
    "training_prices_wo_outliers = reject_outliers(X_train_clean['price'].values)\n",
    "# remove points from test set if price was an outlier\n",
    "min_price = min(training_prices_wo_outliers)\n",
    "max_price = max(training_prices_wo_outliers)\n",
    "\n",
    "\n",
    "training_data = pd.concat([X_train_clean, y_train_clean], axis=1)\n",
    "training_clean = training_data.drop(training_data[training_data.price < min_price].index)\n",
    "training_clean = training_clean.drop(training_clean[training_clean.price > max_price].index)\n",
    "\n",
    "X_train_outlier_clean = training_clean[training_clean.columns[:-1].tolist()]\n",
    "y_train_outlier_clean = training_clean['points'].values.reshape(-1, 1)\n",
    "print(\"Training data without outliers\", X_train_outlier_clean.shape, y_train_outlier_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply linear regression again\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train_outlier_clean, y_train_outlier_clean)\n",
    "y_predictions_4 = lm.predict(X_test)\n",
    "\n",
    "w = model.coef_ # parameters of model\n",
    "b = model.intercept_ #intercept of model\n",
    "\n",
    "# print(\"coeficient: \", w)\n",
    "# print(\"intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "# store results for chart 4\n",
    "ax4_y_test = deepcopy(y_test)\n",
    "ax4_y_predictions = deepcopy(y_predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "print ('Accuracy:', model.score(X_test, y_test))\n",
    "# Root mean squared error (RMSE)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, ax4_y_predictions)))\n",
    "# Mean absolute error (MAE)\n",
    "mae_4 = metrics.mean_absolute_error(y_test, ax4_y_predictions)\n",
    "print('MAE:', mae_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Clean outliers from Test Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store clean test data\n",
    "X_test_clean = deepcopy(X_test)\n",
    "y_test_clean = deepcopy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################ REMOVE OUTLIERS FROM TESTING ##########################\n",
    "print(\"Test data with outliers\", X_test_clean.shape, y_test_clean.shape)\n",
    "# clean prices from testing\n",
    "test_prices_wo_outliers = reject_outliers(X_test_clean.values)\n",
    "# remove points from test set if price was an outlier\n",
    "min_price = min(test_prices_wo_outliers)\n",
    "max_price = max(test_prices_wo_outliers)\n",
    "\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data_clean = test_data.drop(test_data[test_data.price < min_price].index)\n",
    "test_data_clean = test_data_clean.drop(test_data_clean[test_data_clean.price > max_price].index)\n",
    "\n",
    "X_test_outlier_clean = test_data_clean[test_data_clean.columns[:-1].tolist()]\n",
    "y_test_outlier_clean = pd.DataFrame(test_data_clean['points'])\n",
    "print(\"Test data without outliers\", X_test_outlier_clean.shape, y_test_outlier_clean.shape)\n",
    "#######################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression WITH outliers in Training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train) # dirty training\n",
    "y_predictions_1 = lm.predict(X_test_outlier_clean) # clean test\n",
    "\n",
    "w = model.coef_ # parameters of model\n",
    "b = model.intercept_ #intercept of model\n",
    "\n",
    "# print(\"coeficient: \", w)\n",
    "# print(\"intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "# store results\n",
    "ax1_y_test = deepcopy(y_test_outlier_clean)\n",
    "ax1_y_predictions = deepcopy(y_predictions_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "print ('Accuracy:', model.score(X_test_outlier_clean, y_test_outlier_clean))\n",
    "# Root mean squared error (RMSE)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(ax1_y_test, ax1_y_predictions)))\n",
    "# Mean absolute error (MAE)\n",
    "mae_1 = metrics.mean_absolute_error(ax1_y_test, ax1_y_predictions)\n",
    "print('MAE:', mae_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression W/O outliers in Training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply linear regression again\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train_outlier_clean, y_train_outlier_clean)\n",
    "y_predictions_2 = lm.predict(X_test_outlier_clean)\n",
    "\n",
    "w = model.coef_ # parameters of model\n",
    "b = model.intercept_ #intercept of model\n",
    "\n",
    "# print(\"coeficient: \", w)\n",
    "# print(\"intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "# store results\n",
    "ax2_y_test = deepcopy(y_test_outlier_clean)\n",
    "ax2_y_predictions = deepcopy(y_predictions_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "print ('Accuracy:', model.score(X_test_clean, y_test_clean))\n",
    "# Root mean squared error (RMSE)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(ax2_y_test, y_predictions_2)))\n",
    "# Mean absolute error (MAE)\n",
    "mae_2 = metrics.mean_absolute_error(ax2_y_test, y_predictions_2)\n",
    "print('MAE:', mae_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SUMMARY</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from IPython.display import HTML, display\n",
    "\n",
    " data = [[\"Training\\Test\", \"W/ OUTLIERS\",\"W/O OUTLIERS\"],\n",
    "         [\"W/ OUTLIERS\",mae_3, mae_1],\n",
    "         [\"W/O OUTLIERS\",mae_4, mae_2],\n",
    "         ]\n",
    "\n",
    " display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax3, ax4), (ax1, ax2)) = plt.subplots(2, 2, sharey=True, figsize=(15,15))\n",
    "\n",
    "# Dirty test outliers\n",
    "print(\"************OUTLIERS IN TEST DATA **************\")\n",
    "# plot w/ outliers in training data\n",
    "ax3.scatter(ax3_y_test, ax3_y_predictions)\n",
    "ax3.set(xlabel='True Values', ylabel='Predictions')\n",
    "\n",
    "max_y_predictions = int(max(ax3_y_predictions))\n",
    "min_y_predictions = int(min(ax3_y_predictions))\n",
    "\n",
    "print(\"--> TEST OUTLIERS AND TRAINING OUTLIERS\")\n",
    "print('max_y_predictions: ', max_y_predictions)\n",
    "print('min_y_predictions: ', min_y_predictions)\n",
    "print('MAE:', mae_3)\n",
    "print()\n",
    "\n",
    "max_y_true = int(max(ax3_y_test.points))\n",
    "min_y_true = int(min(ax3_y_test.points))\n",
    "\n",
    "ax3.axhline(max_y_true,label='max true value', color=\"red\")\n",
    "\n",
    "ax3.legend()\n",
    "ax3.grid()\n",
    "ax3.set_xlim([80,100])\n",
    "ax3.set_ylim([80,100])\n",
    "ax3.set_title('TEST OUTLIERS AND TRAINING OUTLIERS')\n",
    "\n",
    "# plot w/o outliers in training data\n",
    "ax4.scatter(ax4_y_test, ax4_y_predictions)\n",
    "ax4.set(xlabel='True Values', ylabel='Predictions')\n",
    "\n",
    "max_y_predictions = int(max(ax4_y_predictions))\n",
    "min_y_predictions = int(min(ax4_y_predictions))\n",
    "\n",
    "print(\"--> ONLY OUTLIERS IN TEST\")\n",
    "print('max_y_predictions: ', max_y_predictions)\n",
    "print('min_y_predictions: ', min_y_predictions)\n",
    "print('MAE:', mae_4)\n",
    "\n",
    "max_y_true = int(max(ax4_y_test.points))\n",
    "min_y_true = int(min(ax4_y_test.points))\n",
    "\n",
    "ax4.axhline(max_y_true,label='max true value', color=\"red\")\n",
    "\n",
    "ax4.legend()\n",
    "ax4.grid()\n",
    "ax4.set_xlim([80,100])\n",
    "ax4.set_ylim([80,100])\n",
    "ax4.set_title('ONLY OUTLIERS IN TEST')\n",
    "\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "\n",
    "print()\n",
    "\n",
    "# Clean test\n",
    "print(\"************CLEAN TEST DATA**************\")\n",
    "# plot w/ outliers in training data\n",
    "ax1.scatter(ax1_y_test, ax1_y_predictions)\n",
    "ax1.set(xlabel='True Values', ylabel='Predictions')\n",
    "\n",
    "max_y_predictions = int(max(ax1_y_predictions))\n",
    "min_y_predictions = int(min(ax1_y_predictions))\n",
    "\n",
    "print(\"--> ONLY OUTLIERS IN TRAINING:\")\n",
    "print('max_y_predictions: ', max_y_predictions)\n",
    "print('min_y_predictions: ', min_y_predictions)\n",
    "print('MAE:', mae_1)\n",
    "print()\n",
    "\n",
    "max_y_true = int(max(ax1_y_test.points))\n",
    "min_y_true = int(min(ax1_y_test.points))\n",
    "\n",
    "ax1.axhline(max_y_true,label='max true value', color=\"red\")\n",
    "\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "ax1.set_xlim([80,100])\n",
    "ax1.set_ylim([80,100])\n",
    "ax1.set_title('ONLY OUTLIERS IN TRAINING')\n",
    "\n",
    "# plot w/o outliers in training data\n",
    "ax2.scatter(ax2_y_test, ax2_y_predictions)\n",
    "ax2.set(xlabel='True Values', ylabel='Predictions')\n",
    "\n",
    "max_y_predictions = int(max(ax2_y_predictions))\n",
    "min_y_predictions = int(min(ax2_y_predictions))\n",
    "\n",
    "print(\"--> NO OUTLIERS:\")\n",
    "print('max_y_predictions: ', max_y_predictions)\n",
    "print('min_y_predictions: ', min_y_predictions)\n",
    "print('MAE:', mae_2)\n",
    "\n",
    "max_y_true = int(max(ax2_y_test.points))\n",
    "min_y_true = int(min(ax2_y_test.points))\n",
    "\n",
    "ax2.axhline(max_y_true,label='max true value', color=\"red\")\n",
    "\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "ax2.set_xlim([80,100])\n",
    "ax2.set_ylim([80,100])\n",
    "ax2.set_title('NO OUTLIERS')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
