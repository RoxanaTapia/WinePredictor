{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predictor typos in France - MULTI </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Retrieves incrementally dataframes with n% of typos from <i>typos_generator</i></b>\n",
    "* <b>In each case, executes one hot encoding of categorical variables</b>\n",
    "* <b>Retrieves base MSE of data with n-typos</b>\n",
    "* <b>Stores metrics for further statistics</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from typos_generator.ipynb\n",
      "['US' 'Spain' 'Italy' 'France' 'Argentina' 'Australia' 'Canada']\n",
      "US           53116\n",
      "France       16319\n",
      "Italy        16069\n",
      "Spain         6059\n",
      "Argentina     3664\n",
      "Australia     2223\n",
      "Canada         253\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import copy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics  \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "import import_ipynb\n",
    "import typos_generator as typos_generator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "      <th>points</th>\n",
       "      <th>year_of_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>87</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>87</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>87</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Navarra</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "      <td>87</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index country        province               region  price  \\\n",
       "0      0      US          Oregon    Willamette Valley   14.0   \n",
       "1      1      US        Michigan  Lake Michigan Shore   13.0   \n",
       "2      2      US          Oregon    Willamette Valley   65.0   \n",
       "3      3   Spain  Northern Spain              Navarra   15.0   \n",
       "\n",
       "              variety  points  year_of_wine  \n",
       "0          Pinot Gris      87          2013  \n",
       "1            Riesling      87          2013  \n",
       "2          Pinot Noir      87          2012  \n",
       "3  Tempranillo-Merlot      87          2011  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wine Dataset\n",
    "df_wine = pd.read_csv(\"df_wine_horizontal_tests.csv\", encoding = 'utf8', index_col=0)\n",
    "df_wine = df_wine.reset_index()\n",
    "# check data\n",
    "df_wine.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "# df_wine = df_wine.drop(['province', 'region', 'price', 'variety', 'year_of_wine'], axis=1)\n",
    "# df_wine.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_wine.drop('points', axis=1)\n",
    "df_Y = df_wine[['points']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "      <th>year_of_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82970</th>\n",
       "      <td>86163</td>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>4766</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27058</th>\n",
       "      <td>28094</td>\n",
       "      <td>France</td>\n",
       "      <td>Burgundy</td>\n",
       "      <td>Saint-Véran</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84009</th>\n",
       "      <td>87245</td>\n",
       "      <td>France</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Blaye Côtes de Bordeaux</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index country    province                   region  price  \\\n",
       "82970  86163      US  California                     Napa  100.0   \n",
       "4606    4766      US    New York              Long Island   40.0   \n",
       "27058  28094  France    Burgundy              Saint-Véran   30.0   \n",
       "84009  87245  France    Bordeaux  Blaye Côtes de Bordeaux   15.0   \n",
       "\n",
       "                        variety  year_of_wine  \n",
       "82970        Cabernet Sauvignon          2013  \n",
       "4606            Sauvignon Blanc          2013  \n",
       "27058                Chardonnay          2014  \n",
       "84009  Bordeaux-style Red Blend          2016  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_copy = copy.deepcopy(X_train)\n",
    "X_train_copy.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US           37282\n",
      "France       11412\n",
      "Italy        11173\n",
      "Spain         4227\n",
      "Argentina     2563\n",
      "Australia     1568\n",
      "Canada         167\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check number of US values in X_train\n",
    "frequencies = X_train_copy[\"country\"].value_counts()\n",
    "frequencies.sort_values\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding (constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns=['country'])\n",
    "X_test = pd.get_dummies(X_test, columns=['province'])\n",
    "X_test = pd.get_dummies(X_test, columns=['region'])\n",
    "X_test = pd.get_dummies(X_test, columns=['variety'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting: number of experinents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [10, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Typos in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "[OK] Inserting typos in 1141 out of 11412 rows in France. (10%)\n",
      "[OK] Experiment 1: \n",
      "Mean Absolute Error: 2.1937\n",
      "Mean Squared Error: 8.8333\n",
      "Root Mean Squared Error: 2.9721\n",
      "Elapsed time:  17.19\n",
      "****************************************************************************************************\n",
      "[OK] Inserting typos in 2282 out of 11412 rows in France. (20%)\n",
      "[OK] Experiment 2: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4a81e177333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# one hot encoding (variable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX_train_typos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_typos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mX_train_typos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_typos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'province'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mX_train_typos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_typos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mX_train_typos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_typos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variety'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 include=dtypes_to_encode)\n\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   2783\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_take'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2785\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m         new_data = self._data.take(indices,\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4439\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   4426\u001b[0m         \"\"\"\n\u001b[1;32m   4427\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4428\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4436\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4096\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4098\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   5067\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 5069\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5071\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dojo3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   5090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5092\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5093\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "results = list()\n",
    "\n",
    "\n",
    "typos = list()\n",
    "\n",
    "for X_train_typos in typos_generator.generate_dirty_data(X_train_copy, \"country\", \"France\", n):\n",
    "    # store data with typos for further cleaning\n",
    "    typos.append(X_train_typos)\n",
    "    \n",
    "    print(\"[OK] Experiment {}: \".format(i+1))\n",
    "    start_time = time.time()\n",
    "    # get hyperparameters\n",
    "    # max_depth, min_samples_split = get_hyperparameters(X_train, y_train)\n",
    "    # print(\"max_depth: {}, min_samples_split: {}\".format(max_depth, min_samples_split))\n",
    "    \n",
    "    # one hot encoding (variable)\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['country'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['province'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['region'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['variety'])\n",
    "    \n",
    "    X_train_typos, X_test = X_train_typos.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "    \n",
    "    # print(X_train_typos.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # apply regression\n",
    "    regressor = DecisionTreeRegressor()  \n",
    "    regressor.fit(X_train_typos, y_train) # Train the model using the training sets\n",
    "    y_pred = regressor.predict(X_test) # Make predictions using the testing set\n",
    "\n",
    "    # The evaluation metrics\n",
    "    mae = round(metrics.mean_absolute_error(y_test, y_pred), 4)\n",
    "    mse = round(metrics.mean_squared_error(y_test, y_pred), 4)\n",
    "    rmse = round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 4)\n",
    "    elapsed_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "    print('Mean Absolute Error:', mae)  \n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('Elapsed time: ', elapsed_time)\n",
    "    print(\"*****\"*20)\n",
    "    \n",
    "    # store results\n",
    "    result = dict(\n",
    "        n=i+1,\n",
    "        columns=len(X_train_typos.columns),\n",
    "        elapsed_time=elapsed_time,\n",
    "        results=dict(mae=mae, mse=mse, rmse=rmse)\n",
    "    )\n",
    "    results.append(result)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predictor cleaned typos in country </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Iterates through dataframes with n% of typos (previously stored)</b>\n",
    "* <b>In each case, detects and clean typos</b>\n",
    "* <b>In each case, executes one hot encoding of categorical variables</b>\n",
    "* <b>Retrieves base MSE of data with n-typos</b>\n",
    "* <b>Stores metrics for further statistics</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typos cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value, original, percent):\n",
    "    typos_chars = list(value)\n",
    "    items = list(original)\n",
    "    \n",
    "    check_list = dict()\n",
    "    for item in items:\n",
    "        check_list[item] = False\n",
    "    \n",
    "    # check if value contains all chars of original\n",
    "    for typo in typos_chars:\n",
    "        if typo in original:\n",
    "            if check_list[typo]:\n",
    "                continue\n",
    "            check_list[typo] = True\n",
    "    \n",
    "    # how many characters from the original were found, \n",
    "    # correctnes 100 means, all characters in the original were found\n",
    "    correctness = int((percent * len(original)) / 100.0)\n",
    "    corrected = len([x for x in check_list.values() if x])\n",
    "\n",
    "    if corrected < correctness:\n",
    "    # print(\"[ERROR] Couldnt clean: {}.\".format(value))\n",
    "        return value\n",
    "\n",
    "    return original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typos detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_typos(df, column_name, column_value, expected_distinct_values, correctness):\n",
    "    i = 0\n",
    "    b = 0\n",
    "    print(\"[OK] Clean correctness: {}%\".format(correctness))\n",
    "    for index, row in df.iterrows():\n",
    "        value = row[column_name]\n",
    "        if value in expected_distinct_values:\n",
    "            continue\n",
    "        \n",
    "        new_value = clean_value(value, column_value, correctness)\n",
    "        \n",
    "        if value != new_value:\n",
    "            df.at[index, column_name] = new_value\n",
    "            # print(\"[OK] Cleaning {} results in {}\".format(value, new_value))\n",
    "            i += 1\n",
    "        else:\n",
    "            # discard the row that couldnt be cleaned\n",
    "            # df.at[index, column_name] = np.NaN\n",
    "            b += 1\n",
    "    \n",
    "    # print(\"[OK] Typos detected: {}\".format(b+i))\n",
    "    # print(\"[OK] Cleaned: {} rows\".format(i))\n",
    "    print(\"[WARN] Couldn't clean {} rows\".format(b)) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result CLEANED typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning settings\n",
    "expected_distinct_values = ['US', 'Spain', 'Italy', 'France', 'Argentina', 'Australia', 'Canada']\n",
    "correctness = 100\n",
    "\n",
    "i = 0\n",
    "results = list()\n",
    "\n",
    "\n",
    "for X_train_typos in typos:\n",
    "    print(\"[OK] Experiment {}: \".format(i+1))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # data detect and clean\n",
    "    X_train_typos = detect_typos(X_train_typos, \"country\", \"France\", expected_distinct_values, correctness)\n",
    "    \n",
    "    # one hot encoding (variable)\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['country'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['province'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['region'])\n",
    "    X_train_typos = pd.get_dummies(X_train_typos, columns=['variety'])\n",
    "    \n",
    "    X_train_typos, X_test = X_train_typos.align(X_test, join='outer', axis=1, fill_value=0)\n",
    "    \n",
    "    # print(X_train_typos.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # apply regression\n",
    "    regressor = DecisionTreeRegressor()  \n",
    "    regressor.fit(X_train_typos, y_train) # Train the model using the training sets\n",
    "    y_pred = regressor.predict(X_test) # Make predictions using the testing set\n",
    "\n",
    "    # The evaluation metrics\n",
    "    mae = round(metrics.mean_absolute_error(y_test, y_pred), 4)\n",
    "    mse = round(metrics.mean_squared_error(y_test, y_pred), 4)\n",
    "    rmse = round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 4)\n",
    "    elapsed_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "    print('Mean Absolute Error:', mae)  \n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('Elapsed time: ', elapsed_time)\n",
    "    print(\"*****\"*20)\n",
    "    \n",
    "    # store results\n",
    "    result = dict(\n",
    "        n=i+1,\n",
    "        columns=len(X_train_typos.columns),\n",
    "        elapsed_time=elapsed_time,\n",
    "        results=dict(mae=mae, mse=mse, rmse=rmse)\n",
    "    )\n",
    "    results.append(result)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
